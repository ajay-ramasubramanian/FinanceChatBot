{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6650bde-0539-469e-8fb3-8adcf9e878b6",
   "metadata": {
    "id": "f6650bde-0539-469e-8fb3-8adcf9e878b6"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install requests beautifulsoup4  sentence-transformers transformers\n",
    "!pip install git+https://github.com/huggingface/accelerate\n",
    "!pip install langchain chromadb langchain\n",
    "!pip install langchain_chroma langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52a13e1f-6701-499f-925d-bfe5bde64f04",
   "metadata": {
    "id": "52a13e1f-6701-499f-925d-bfe5bde64f04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=AAPL&type=10-K&dateb=&owner=exclude&count=100&output=xml\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define your user agent string\n",
    "headers = {'User-Agent': 'Your Name - your_email@example.com'}\n",
    "\n",
    "def get_filings(ticker, filing_type=\"10-K\"):\n",
    "    url = f\"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={ticker}&type={filing_type}&dateb=&owner=exclude&count=100&output=xml\"\n",
    "    print(url)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "        return None\n",
    "ticker=\"AAPL\"\n",
    "filings_xml = get_filings(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf990e81-03cd-41e8-8a4c-75bfa23aa990",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0cc1b56-30f9-478d-a7f9-0d4248322ede",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0cc1b56-30f9-478d-a7f9-0d4248322ede",
    "outputId": "15333229-f255-48f7-9e71-2b1c455804a5",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: xml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 31\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m document_link\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m document_url \u001b[38;5;241m=\u001b[39m \u001b[43mparse_filings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilings_xml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(document_url)\n\u001b[0;32m     34\u001b[0m c_document_url\u001b[38;5;241m=\u001b[39mdocument_url\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mix?doc=/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 10\u001b[0m, in \u001b[0;36mparse_filings\u001b[1;34m(filings_xml)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_filings\u001b[39m(filings_xml):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    Gets the link from the \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=MSFT&type=10-K&dateb=&owner=exclude&count=100&output=xml\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    to Retrieve the target document from \"https://www.sec.gov/Archives/edgar/data/789019/000095017023035122/0000950170-23-035122.txt\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilings_xml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Parse as XML\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     links \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilingHREF\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# print(links)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# print(links)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\bs4\\__init__.py:250\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[0;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features))\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: xml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import requests, os\n",
    "from bs4 import BeautifulSoup,NavigableString\n",
    "import re\n",
    "import pandas as pd\n",
    "def parse_filings(filings_xml):\n",
    "    \"\"\"\n",
    "    Gets the link from the \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=MSFT&type=10-K&dateb=&owner=exclude&count=100&output=xml\"\n",
    "    to Retrieve the target document from \"https://www.sec.gov/Archives/edgar/data/789019/000095017023035122/0000950170-23-035122.txt\"\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(filings_xml, 'xml')  # Parse as XML\n",
    "    links = soup.find_all('filingHREF')\n",
    "    # print(links)\n",
    "    # print(links)\n",
    "    for link in links:\n",
    "        filing_page_url = link.text\n",
    "        # print(filing_page_url)\n",
    "        # Fetch the filing page content\n",
    "        filing_page_content = requests.get(filing_page_url,headers=headers).text\n",
    "        # print(filing_page_content)\n",
    "        # Parse the filing page content\n",
    "        filing_page_soup = BeautifulSoup(filing_page_content, 'html.parser')\n",
    "        \n",
    "        # Search for the target document link within the filing page\n",
    "        document_link = filing_page_soup.find('a', href=lambda href: href and href.endswith('.txt'))\n",
    "        # print(document_link)\n",
    "        if document_link:\n",
    "            return document_link.get('href')\n",
    "    \n",
    "    return None\n",
    "\n",
    "document_url = parse_filings(filings_xml)\n",
    "print(document_url)\n",
    "\n",
    "c_document_url=document_url.replace(\"ix?doc=/\",\"\")\n",
    "base_url =\"https://www.sec.gov\"\n",
    "if document_url:\n",
    "    print(f\"Document URL: {base_url+c_document_url}\")\n",
    "else:\n",
    "    print(f\"Document {target_document} not found in filings XML\")\n",
    "\n",
    "raw_10k = requests.get(base_url+c_document_url, headers=headers).text\n",
    "# print(raw_10k[0:1400])\n",
    "\n",
    "\n",
    "# Regex to find <DOCUMENT> tags\n",
    "doc_start_pattern = re.compile(r'<DOCUMENT>')\n",
    "doc_end_pattern = re.compile(r'</DOCUMENT>')\n",
    "# Regex to find <TYPE> tag prceeding any characters, terminating at new line\n",
    "type_pattern = re.compile(r'<TYPE>[^\\n]+')\n",
    "\n",
    "# Create 3 lists with the span idices for each regex\n",
    "\n",
    "### There are many <Document> Tags in this text file, each as specific exhibit like 10-K, EX-10.17 etc\n",
    "### First filter will give us document tag start <end> and document tag end's <start> \n",
    "### We will use this to later grab content in between these tags\n",
    "doc_start_is = [x.end() for x in doc_start_pattern.finditer(raw_10k)]\n",
    "doc_end_is = [x.start() for x in doc_end_pattern.finditer(raw_10k)]\n",
    "\n",
    "### Type filter is interesting, it looks for <TYPE> with Not flag as new line, ie terminare there, with + sign\n",
    "### to look for any char afterwards until new line \\n. This will give us <TYPE> followed Section Name like '10-K'\n",
    "### Once we have have this, it returns String Array, below line will with find content after <TYPE> ie, '10-K' \n",
    "### as section names\n",
    "doc_types = [x[len('<TYPE>'):] for x in type_pattern.findall(raw_10k)]\n",
    "\n",
    "document = {}\n",
    "\n",
    "# Create a loop to go through each section type and save only the 10-K section in the dictionary\n",
    "for doc_type, doc_start, doc_end in zip(doc_types, doc_start_is, doc_end_is):\n",
    "    if doc_type == '10-K':\n",
    "        document[doc_type] = raw_10k[doc_start:doc_end]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Write the regex\n",
    "regex = re.compile(r'(>Item(\\s|&#160;|&nbsp;)(1A|1B|7A|7|8|9)\\.{0,1})|(ITEM\\s(1A|1B|7A|7|8|9))')\n",
    "\n",
    "# Use finditer to math the regex\n",
    "matches = regex.finditer(document['10-K'])\n",
    "\n",
    "# Write a for loop to print the matches\n",
    "for match in matches:\n",
    "    print(match)\n",
    "\n",
    "# Matches\n",
    "matches = regex.finditer(document['10-K'])\n",
    "\n",
    "# Create the dataframe\n",
    "test_df = pd.DataFrame([(x.group(), x.start(), x.end()) for x in matches])\n",
    "\n",
    "test_df.columns = ['item', 'start', 'end']\n",
    "test_df['item'] = test_df.item.str.lower()\n",
    "\n",
    "# Display the dataframe\n",
    "\n",
    "test_df.replace('&#160;',' ',regex=True,inplace=True)\n",
    "test_df.replace('&nbsp;',' ',regex=True,inplace=True)\n",
    "test_df.replace(' ','',regex=True,inplace=True)\n",
    "test_df.replace('\\.','',regex=True,inplace=True)\n",
    "test_df.replace('>','',regex=True,inplace=True)\n",
    "test_df.head()\n",
    "\n",
    "# Drop duplicates\n",
    "pos_dat = test_df.sort_values('start', ascending=True).drop_duplicates(subset=['item'], keep='last')\n",
    "\n",
    "# Set item as the dataframe index\n",
    "pos_dat.set_index('item', inplace=True)\n",
    "\n",
    "# Get Item 1a\n",
    "item_1a_raw = document['10-K'][pos_dat['start'].loc['item1a']:pos_dat['start'].loc['item1b']]\n",
    "\n",
    "# Get Item 7\n",
    "item_7_raw = document['10-K'][pos_dat['start'].loc['item7']:pos_dat['start'].loc['item7a']]\n",
    "\n",
    "# Get Item 7a\n",
    "item_7a_raw = document['10-K'][pos_dat['start'].loc['item7a']:pos_dat['start'].loc['item8']]\n",
    "\n",
    "item_8_raw = document['10-K'][pos_dat['start'].loc['item8']:pos_dat['end'].loc['item9']]\n",
    "\n",
    "item_8_raw[0:1000]\n",
    "# exit()\n",
    "# def get_text_from_innermost_tags(tag):\n",
    "#     if isinstance(tag, NavigableString):\n",
    "#         return tag.strip()\n",
    "#     else:\n",
    "#         # Check if this tag contains other tags\n",
    "#         if tag.find() is not None:\n",
    "#             # This tag contains other tags, so ignore it\n",
    "#             return ''\n",
    "#         else:\n",
    "#             # This tag does not contain other tags, so extract its text\n",
    "#             return tag.get_text(separator='\\n', strip=True) +'\\n'\n",
    "            \n",
    "# soup = BeautifulSoup(html_content, 'html.parser')\n",
    "# start_tag = soup.find(lambda tag: tag.name == \"span\" and \"UNITED STATES\" in tag.get_text())\n",
    "# # print(start_tag)\n",
    "# if start_tag:\n",
    "#     # Extract the HTML from the starting tag onwards\n",
    "#     relevant_content = start_tag.get_text(separator='\\n', strip= True)\n",
    "#     for element in start_tag.find_all_next():\n",
    "#         # print(element)\n",
    "#         relevant_content += get_text_from_innermost_tags(element) \n",
    "# else:\n",
    "#     print(\"Starting point not found in the document\")\n",
    "#     relevant_content = \"\"\n",
    "\n",
    "# # print(relevant_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7ed61-e161-4378-9e64-245d2b0572f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29a7ed61-e161-4378-9e64-245d2b0572f7",
    "outputId": "9a0ebdf6-e4ef-4c11-8454-77b202f872aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1250, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1765, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1028, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1355, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1428, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1624, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1787, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1476, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1292, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1128, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2189, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1529, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1079, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1771, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2755, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1295, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1824, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 3200, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1786, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2636, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2686, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1552, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1472, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1410, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1247, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1691, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1322, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1506, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1283, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1245, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1821, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1373, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2491, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1823, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 4390, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1642, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1351, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1880, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1599, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 3491, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 4173, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2058, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1056, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2198, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 5541, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 4105, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 5355, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1011, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 3440, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1093, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 3210, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1841, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 5180, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 3138, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1939, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2195, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1698, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1902, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1469, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1513, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1037, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2515, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1134, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1296, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1713, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1391, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1665, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2220, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2094, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1033, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1056, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1129, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1559, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1029, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1255, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1982, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1409, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1106, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1396, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1110, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1528, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1781, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2273, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1746, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1648, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1225, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1670, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1051, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1287, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1019, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 3850, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1259, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1325, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1244, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1011, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 2896, which is longer than the specified 1000\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n",
      "\n",
      "\n",
      "2022\n",
      "\n",
      "\n",
      "2021\n",
      "\n",
      "Net income\n",
      "\n",
      "$\n",
      "72,361\n",
      "\n",
      "\n",
      "$\n",
      "72,738\n",
      "\n",
      "\n",
      "$\n",
      "61,271\n",
      "\n",
      "Other comprehensive income (loss), net of tax:\n",
      "\n",
      "\n",
      "Net change related to derivatives\n",
      "\n",
      "\n",
      "(\n",
      "14\n",
      ")\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "19\n",
      "\n",
      "Net change related to investments\n",
      "\n",
      "\n",
      "(\n",
      "1,444\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "5,360\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "2,266\n",
      ")\n",
      "Translation adjustments and other\n",
      "\n",
      "\n",
      "(\n",
      "207\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "1,146\n",
      ")\n",
      "\n",
      "\n",
      "873\n",
      "\n",
      "\n",
      "Other comprehensive loss\n",
      "\n",
      "\n",
      "(\n",
      "1,665\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "6,500\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "1,374\n",
      ")\n",
      "\n",
      "Comprehensive income\n",
      "\n",
      "$\n",
      "70,696\n",
      "\n",
      "\n",
      "$\n",
      "66,238\n",
      "\n",
      "\n",
      "$\n",
      "59,897\n",
      "\n",
      "Refer to accompanying notes.\n",
      "\n",
      "59\n",
      "\n",
      "PART II\n",
      "Item 8\n",
      "\n",
      "BALANCE\n",
      "SHEETS\n",
      "\n",
      "(In millions)\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "with open('output.txt', 'w') as file:\n",
    "    file.write(relevant_content)\n",
    "\n",
    "loader = TextLoader('output.txt')\n",
    "documents= loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size =1000, chunk_overlap =200)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embedding_function = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "db = Chroma.from_documents(docs,embedding=embedding_function)\n",
    "\n",
    "query = \"what is the net Income for the year 2023\"\n",
    "docs= db.similarity_search(query)\n",
    "\n",
    "print(docs[0].page_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Uj_YqG84H8V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124,
     "referenced_widgets": [
      "8317bb7e35da4820a9785e2e03facf2d",
      "383a419439bb484c8001b0c1925dab10",
      "cec82f6f0a454603bcd7c21c319e3544",
      "cf7f4aaa7b7f4252aaea8df62ee395c4",
      "bce79a25af7b4c08a710227a59a89f22",
      "bb0daaa8dd054d6e9dc5ea42359b6c6d",
      "3981ebe88e2f4f548c33057ff6f086be",
      "570a9269979d4931b59a76dab9e26bb1",
      "14562004d37148dd88e6e075788aa2d2",
      "b07dd448126040f3b6b8b038d820e461",
      "ac5cb3c656a048d5ad52eddc145a8367"
     ]
    },
    "id": "5Uj_YqG84H8V",
    "outputId": "21bdcd6c-022d-4cc8-fe8b-73403d401633"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.5be6479b4bc06a081e8f4c6ece294241ccd32dec.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-128k-instruct.5be6479b4bc06a081e8f4c6ece294241ccd32dec.modeling_phi3:Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8317bb7e35da4820a9785e2e03facf2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch, accelerate\n",
    "\n",
    "device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_name_or_path = \"TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ\"\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"gptq-4bit-32g-actorder_True\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"main\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''<|im_start|>system\n",
    "{system_message}<|im_end|>\n",
    "<|im_start|>user\n",
    "{prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "'''\n",
    "\n",
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "# Inference can also be done using transformers' pipeline\n",
    "\n",
    "print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "print(pipe(prompt_template)[0]['generated_text'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nY7P4XiBXE-A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nY7P4XiBXE-A",
    "outputId": "ad982489-be0f-4762-99e0-6318b89f9725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Userquery :What is the Debt ratio of this company?\n",
      "\n",
      "Amount\n",
      "\n",
      "\n",
      "Weighted\n",
      "Average Life\n",
      "\n",
      "Year Ended June 30,\n",
      "\n",
      "2023\n",
      "\n",
      "2022\n",
      "\n",
      "Technology-based\n",
      "\n",
      "$\n",
      "522\n",
      "\n",
      "7\n",
      "years\n",
      "\n",
      "\n",
      "$\n",
      "2,611\n",
      "\n",
      "4\n",
      "years\n",
      "\n",
      "Customer-related\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "0\n",
      "years\n",
      "\n",
      "2,837\n",
      "\n",
      "9\n",
      "years\n",
      "\n",
      "Marketing-related\n",
      "\n",
      "\n",
      "7\n",
      "\n",
      "5\n",
      "years\n",
      "\n",
      "233\n",
      "\n",
      "4\n",
      "years\n",
      "\n",
      "Contract-based\n",
      "\n",
      "\n",
      "12\n",
      "\n",
      "3\n",
      "years\n",
      "\n",
      "0\n",
      "\n",
      "0\n",
      "years\n",
      "\n",
      "\n",
      "Total\n",
      "\n",
      "$\n",
      "541\n",
      "\n",
      "6\n",
      "years\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "5,681\n",
      "\n",
      "7\n",
      "years\n",
      "\n",
      "Intangible assets amortization expense was $\n",
      "2.5\n",
      "billion, $\n",
      "2.0\n",
      "billion, and $\n",
      "1.6\n",
      "billion for fiscal years 2023, 2022, and 2021, respectively.\n",
      "\n",
      "80\n",
      "\n",
      "PART II\n",
      "Item 8\n",
      "\n",
      "The following table outlines the estimated future amortization expense related to intangible assets held as of June 30, 2023:\n",
      "\n",
      "\n",
      "(In millions)\n",
      "\n",
      "\n",
      "Year Ending June 30,\n",
      "\n",
      "\n",
      "2024\n",
      "\n",
      "$\n",
      "2,363\n",
      "\n",
      "2025\n",
      "\n",
      "\n",
      "1,881\n",
      "\n",
      "2026\n",
      "\n",
      "\n",
      "1,381\n",
      "\n",
      "2027\n",
      "\n",
      "\n",
      "929\n",
      "\n",
      "2028\n",
      "\n",
      "\n",
      "652\n",
      "\n",
      "Thereafter\n",
      "\n",
      "\n",
      "2,160\n",
      "\n",
      "\n",
      "Total\n",
      "\n",
      "$\n",
      "9,366\n",
      "\n",
      "NOTE 11 — DEBT\n",
      "\n",
      "The components of debt were as follows:\n",
      "\n",
      "(In millions, issuance by calendar year)\n",
      "\n",
      "Maturities\n",
      "(calendar year)\n",
      "\n",
      "Stated Interest\n",
      "Rate\n",
      "\n",
      "\n",
      "Effective Interest\n",
      "Rate\n",
      "\n",
      "June 30,\n",
      "2023\n",
      "\n",
      "\n",
      "June 30,\n",
      "2022\n",
      "\n",
      "\n",
      "2009\n",
      "issuance of $\n",
      "3.8\n",
      "billion\n",
      "\n",
      "2039\n",
      "\n",
      "\n",
      "5.20\n",
      "%\n",
      "\n",
      "\n",
      "5.24\n",
      "%\n",
      " Context:(\n",
      "737\n",
      ")\n",
      "Other current assets\n",
      "\n",
      "\n",
      "(\n",
      "1,991\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "709\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "932\n",
      ")\n",
      "Other long-term assets\n",
      "\n",
      "\n",
      "(\n",
      "2,833\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "2,805\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "3,459\n",
      ")\n",
      "Accounts payable\n",
      "\n",
      "\n",
      "(\n",
      "2,721\n",
      ")\n",
      "\n",
      "\n",
      "2,943\n",
      "\n",
      "2,798\n",
      "\n",
      "Unearned revenue\n",
      "\n",
      "\n",
      "5,535\n",
      "\n",
      "5,109\n",
      "\n",
      "4,633\n",
      "\n",
      "Income taxes\n",
      "\n",
      "\n",
      "(\n",
      "358\n",
      ")\n",
      "\n",
      "\n",
      "696\n",
      "\n",
      "(\n",
      "2,309\n",
      ")\n",
      "Other current liabilities\n",
      "\n",
      "\n",
      "2,272\n",
      "\n",
      "2,344\n",
      "\n",
      "4,149\n",
      "\n",
      "Other long-term liabilities\n",
      "\n",
      "\n",
      "553\n",
      "\n",
      "825\n",
      "\n",
      "1,402\n",
      "\n",
      "\n",
      "Net cash from operations\n",
      "\n",
      "\n",
      "87,582\n",
      "\n",
      "89,035\n",
      "\n",
      "76,740\n",
      "\n",
      "\n",
      "Financing\n",
      "\n",
      "\n",
      "Cash premium on debt exchange\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "0\n",
      "\n",
      "(\n",
      "1,754\n",
      ")\n",
      "Repayments of debt\n",
      "\n",
      "\n",
      "(\n",
      "2,750\n",
      ")\n",
      "\n",
      "\n",
      "(\n",
      "9,023\n",
      ")\n",
      " Context:Debt Proceeds\n",
      "We issue debt to take advantage of favorable pricing and liquidity in the debt markets, reflecting our credit rating and the low interest rate environment. The proceeds of these issuances were or will be used for general corporate purposes, which may include, among other things, funding for working capital, capital expenditures, repurchases of capital stock, acquisitions, and repayment of existing debt. Refer to Note 11 – Debt of the Notes to Financial Statements (Part II, Item 8 of this Form 10-K)\n",
      "\n",
      "for further discussion.\n",
      "Unearned Revenue\n",
      " Context:Debt Proceeds\n",
      "We issue debt to take advantage of favorable pricing and liquidity in the debt markets, reflecting our credit rating and the low interest rate environment. The proceeds of these issuances were or will be used for general corporate purposes, which may include, among other things, funding for working capital, capital expenditures, repurchases of capital stock, acquisitions, and repayment of existing debt. Refer to Note 11 – Debt of the Notes to Financial Statements (Part II, Item 8 of this Form 10-K)\n",
      "\n",
      "for further discussion.\n",
      "\n",
      "\n",
      "\n",
      "Debt ratio = Total liabilities / Total assets\n",
      "\n",
      "Total liabilities = Accounts payable + Unearned revenue + Income taxes + Other current liabilities + Other long-term liabilities\n",
      "\n",
      "Total assets = Other current assets + Other long-term assets + Total debt\n",
      "\n",
      "Total debt = $541 million + $2,611 million + $2,837 million + $932 million + $1,402 million = $7,323 million\n",
      "\n",
      "Total liabilities = $2,721 million + $5,535 million + $696 million + $2,344 million + $1,402 million = $12,698 million\n",
      "\n",
      "Total assets = $1,991 million + $2,833 million + $7,323 million\n"
     ]
    }
   ],
   "source": [
    "query= \"What is the Debt ratio of this company?\"\n",
    "retriever = db.as_retriever(k=1)\n",
    "relevant_chunks = retriever.invoke(query)\n",
    "chunk_texts = [doc.page_content for doc in relevant_chunks]\n",
    "combined_input = \"Userquery :\" + query + \"\\n\\n\" + \"\\n Context:\".join(chunk_texts)\n",
    "\n",
    "input_ids = tokenizer(combined_input, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "output = model.generate(input_ids, max_new_tokens=200, num_return_sequences=1)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8r_S9ODQVCUR",
   "metadata": {
    "id": "8r_S9ODQVCUR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Assume you have some model and data loaded\n",
    "# model = ...\n",
    "# inputs = ...\n",
    "\n",
    "# Perform operations\n",
    "# output = model(inputs)\n",
    "\n",
    "# Now clear GPU memory\n",
    "\n",
    "gc.collect()  # run garbage collection\n",
    "torch.cuda.empty_cache()  # clear the PyTorch cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cXJz25b2AzNs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXJz25b2AzNs",
    "outputId": "4725215d-32ef-4a19-f862-b9a0357c1896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun  8 23:11:36 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   77C    P0              35W /  70W |   7439MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w9Aed_lgDBLc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9Aed_lgDBLc",
    "outputId": "07bb2304-c1c2-4aa5-b9f9-da215ec9d5c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Column 1 |\n",
      "|----------|\n",
      "| Userquery :What is the Debt ratio of this company? |\n",
      "| Amount |\n",
      "| Weighted |\n",
      "| Average Life |\n",
      "| Year Ended June 30, |\n",
      "| 2023 |\n",
      "| 2022 |\n",
      "| Technology-based |\n",
      "| $ |\n",
      "| 522 |\n",
      "| 7 |\n",
      "| years |\n",
      "| $ |\n",
      "| 2,611 |\n",
      "| 4 |\n",
      "| years |\n",
      "| Customer-related |\n",
      "| 0 |\n",
      "| 0 |\n",
      "| years |\n",
      "| 2,837 |\n",
      "| 9 |\n",
      "| years |\n",
      "| Marketing-related |\n",
      "| 7 |\n",
      "| 5 |\n",
      "| years |\n",
      "| 233 |\n",
      "| 4 |\n",
      "| years |\n",
      "| Contract-based |\n",
      "| 12 |\n",
      "| 3 |\n",
      "| years |\n",
      "| 0 |\n",
      "| 0 |\n",
      "| years |\n",
      "| Total |\n",
      "| $ |\n",
      "| 541 |\n",
      "| 6 |\n",
      "| years |\n",
      "| $ |\n",
      "| 5,681 |\n",
      "| 7 |\n",
      "| years |\n",
      "| Intangible assets amortization expense was $ |\n",
      "| 2.5 |\n",
      "| billion, $ |\n",
      "| 2.0 |\n",
      "| billion, and $ |\n",
      "| 1.6 |\n",
      "| billion for fiscal years 2023, 2022, and 2021, respectively. |\n",
      "| 80 |\n",
      "| PART II |\n",
      "| Item 8 |\n",
      "| The following table outlines the estimated future amortization expense related to intangible assets held as of June 30, 2023: |\n",
      "| (In millions) |\n",
      "| Year Ending June 30, |\n",
      "| 2024 |\n",
      "| $ |\n",
      "| 2,363 |\n",
      "| 2025 |\n",
      "| 1,881 |\n",
      "| 2026 |\n",
      "| 1,381 |\n",
      "| 2027 |\n",
      "| 929 |\n",
      "| 2028 |\n",
      "| 652 |\n",
      "| Thereafter |\n",
      "| 2,160 |\n",
      "| Total |\n",
      "| $ |\n",
      "| 9,366 |\n",
      "| NOTE 11 — DEBT |\n",
      "| The components of debt were as follows: |\n",
      "| (In millions, issuance by calendar year) |\n",
      "| Maturities |\n",
      "| (calendar year) |\n",
      "| Stated Interest |\n",
      "| Rate |\n",
      "| Effective Interest |\n",
      "| Rate |\n",
      "| June 30, |\n",
      "| 2023 |\n",
      "| June 30, |\n",
      "| 2022 |\n",
      "| 2009 |\n",
      "| issuance of $ |\n",
      "| 3.8 |\n",
      "| billion |\n",
      "| 2039 |\n",
      "| 5.20 |\n",
      "| % |\n",
      "| 5.24 |\n",
      "| % |\n",
      "| Context:( |\n",
      "| 737 |\n",
      "| ) |\n",
      "| Other current assets |\n",
      "| ( |\n",
      "| 1,991 |\n",
      "| ) |\n",
      "| ( |\n",
      "| 709 |\n",
      "| ) |\n",
      "| ( |\n",
      "| 932 |\n",
      "| ) |\n",
      "| Other long-term assets |\n",
      "| ( |\n",
      "| 2,833 |\n",
      "| ) |\n",
      "| ( |\n",
      "| 2,805 |\n",
      "| ) |\n",
      "| ( |\n",
      "| 3,459 |\n",
      "| ) |\n",
      "| Accounts payable |\n",
      "| ( |\n",
      "| 2,721 |\n",
      "| ) |\n",
      "| 2,943 |\n",
      "| 2,798 |\n",
      "| Unearned revenue |\n",
      "| 5,535 |\n",
      "| 5,109 |\n",
      "| 4,633 |\n",
      "| Income taxes |\n",
      "| ( |\n",
      "| 358 |\n",
      "| ) |\n",
      "| 696 |\n",
      "| ( |\n",
      "| 2,309 |\n",
      "| ) |\n",
      "| Other current liabilities |\n",
      "| 2,272 |\n",
      "| 2,344 |\n",
      "| 4,149 |\n",
      "| Other long-term liabilities |\n",
      "| 553 |\n",
      "| 825 |\n",
      "| 1,402 |\n",
      "| Net cash from operations |\n",
      "| 87,582 |\n",
      "| 89,035 |\n",
      "| 76,740 |\n",
      "| Financing |\n",
      "| Cash premium on debt exchange |\n",
      "| 0 |\n",
      "| 0 |\n",
      "| ( |\n",
      "| 1,754 |\n",
      "| ) |\n",
      "| Repayments of debt |\n",
      "| ( |\n",
      "| 2,750 |\n",
      "| ) |\n",
      "| ( |\n",
      "| 9,023 |\n",
      "| ) |\n",
      "| Context:Debt Proceeds |\n",
      "| We issue debt to take advantage of favorable pricing and liquidity in the debt markets, reflecting our credit rating and the low interest rate environment. The proceeds of these issuances were or will be used for general corporate purposes, which may include, among other things, funding for working capital, capital expenditures, repurchases of capital stock, acquisitions, and repayment of existing debt. Refer to Note 11 – Debt of the Notes to Financial Statements (Part II, Item 8 of this Form 10-K) |\n",
      "| for further discussion. |\n",
      "| Unearned Revenue |\n",
      "| Context:Debt Proceeds |\n",
      "| We issue debt to take advantage of favorable pricing and liquidity in the debt markets, reflecting our credit rating and the low interest rate environment. The proceeds of these issuances were or will be used for general corporate purposes, which may include, among other things, funding for working capital, capital expenditures, repurchases of capital stock, acquisitions, and repayment of existing debt. Refer to Note 11 – Debt of the Notes to Financial Statements (Part II, Item 8 of this Form 10-K) |\n",
      "| for further discussion. |\n",
      "| Debt ratio = Total liabilities / Total assets |\n",
      "| Total liabilities = Accounts payable + Unearned revenue + Income taxes + Other current liabilities + Other long-term liabilities |\n",
      "| Total assets = Other current assets + Other long-term assets + Total debt |\n",
      "| Total debt = $541 million + $2,611 million + $2,837 million + $932 million + $1,402 million = $7,323 million |\n",
      "| Total liabilities = $2,721 million + $5,535 million + $696 million + $2,344 million + $1,402 million = $12,698 million |\n",
      "| Total assets = $1,991 million + $2,833 million + $7,323 million |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def detect_and_convert_to_markdown(text):\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    max_columns = 0\n",
    "\n",
    "    # Helper function to add row if it's complete\n",
    "    def add_row_if_complete():\n",
    "        nonlocal max_columns\n",
    "        if current_row:\n",
    "            rows.append(current_row[:])\n",
    "            if len(current_row) > max_columns:\n",
    "                max_columns = len(current_row)\n",
    "            current_row.clear()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Split the line by spaces, tabs, or other delimiters to detect columns\n",
    "        columns = re.split(r'\\s{2,}|\\t', line)\n",
    "        if len(columns) > 1:\n",
    "            add_row_if_complete()\n",
    "            current_row.extend(columns)\n",
    "            add_row_if_complete()\n",
    "        else:\n",
    "            current_row.append(line)\n",
    "            add_row_if_complete()\n",
    "\n",
    "    # Handle the last row if any\n",
    "    add_row_if_complete()\n",
    "\n",
    "    # Construct the markdown table\n",
    "    if rows:\n",
    "        headers = [\"Column \" + str(i + 1) for i in range(max_columns)]\n",
    "        markdown_table = f\"| {' | '.join(headers)} |\\n\"\n",
    "        markdown_table += f\"|{'|'.join(['-' * (len(header) + 2) for header in headers])}|\\n\"\n",
    "\n",
    "        for row in rows:\n",
    "            markdown_table += f\"| {' | '.join(row + [''] * (max_columns - len(row)))} |\\n\"\n",
    "\n",
    "        return markdown_table\n",
    "    else:\n",
    "        return \"No table detected in the text.\"\n",
    "\n",
    "# Sample input text\n",
    "text = generated_text\n",
    "\n",
    "# Generate the markdown table\n",
    "markdown_table = detect_and_convert_to_markdown(text)\n",
    "print(markdown_table)\n",
    "\n",
    "# Optionally, save to a markdown file\n",
    "with open(\"output_table.md\", \"w\") as file:\n",
    "    file.write(markdown_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5WJWLolXKyvF",
   "metadata": {
    "id": "5WJWLolXKyvF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14562004d37148dd88e6e075788aa2d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "383a419439bb484c8001b0c1925dab10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb0daaa8dd054d6e9dc5ea42359b6c6d",
      "placeholder": "​",
      "style": "IPY_MODEL_3981ebe88e2f4f548c33057ff6f086be",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "3981ebe88e2f4f548c33057ff6f086be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "570a9269979d4931b59a76dab9e26bb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8317bb7e35da4820a9785e2e03facf2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_383a419439bb484c8001b0c1925dab10",
       "IPY_MODEL_cec82f6f0a454603bcd7c21c319e3544",
       "IPY_MODEL_cf7f4aaa7b7f4252aaea8df62ee395c4"
      ],
      "layout": "IPY_MODEL_bce79a25af7b4c08a710227a59a89f22"
     }
    },
    "ac5cb3c656a048d5ad52eddc145a8367": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b07dd448126040f3b6b8b038d820e461": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb0daaa8dd054d6e9dc5ea42359b6c6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bce79a25af7b4c08a710227a59a89f22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cec82f6f0a454603bcd7c21c319e3544": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_570a9269979d4931b59a76dab9e26bb1",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14562004d37148dd88e6e075788aa2d2",
      "value": 2
     }
    },
    "cf7f4aaa7b7f4252aaea8df62ee395c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b07dd448126040f3b6b8b038d820e461",
      "placeholder": "​",
      "style": "IPY_MODEL_ac5cb3c656a048d5ad52eddc145a8367",
      "value": " 2/2 [00:23&lt;00:00, 11.74s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
